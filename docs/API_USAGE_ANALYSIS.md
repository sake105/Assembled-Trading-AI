# API-Nutzung & Performance-Analyse

**Erstellt:** 2025-12-09  
**Status:** Analyse der aktuellen API-Nutzung, Performance-Probleme und Baustellen

---

## 1. API-Provider-√úbersicht

### 1.1 Preis-Daten (Historical)

| Provider | Verwendung | Status | Rate Limits | Performance |
|----------|------------|--------|-------------|-------------|
| **LocalParquetPriceDataSource** | Prim√§r f√ºr alle Workflows | ‚úÖ Empfohlen | Keine | ‚ö° Sehr schnell |
| **YahooPriceDataSource** | Fallback/Live-Daten | ‚ö†Ô∏è Rate-Limits | Unbekannt, oft blockiert | üêå Langsam bei vielen Symbols |
| **FinnhubPriceDataSource** | Alternative f√ºr Preise | ‚ö†Ô∏è Nicht empfohlen | 60/min (Free) | üêå Langsam (Symbol-f√ºr-Symbol) |
| **TwelveDataPriceDataSource** | Alternative f√ºr Preise | ‚ö†Ô∏è Nicht empfohlen | 8/min (Free) | üêå Sehr langsam (Symbol-f√ºr-Symbol) |

**Empfehlung:** 
- **Immer `data_source="local"` verwenden** f√ºr alle Workflows (Backtest, Factor Analysis, etc.)
- Preis-Daten nur √ºber Download-Skripte aktualisieren (z.B. `download_historical_snapshot.py`)
- **NICHT** in Backtests oder Factor-Analysis-Workflows direkt API-Calls f√ºr Preise machen

### 1.2 Alt-Data (Events, News, Macro)

| Provider | Verwendung | Status | Rate Limits | Performance |
|----------|------------|--------|-------------|-------------|
| **Finnhub Events API** | Earnings & Insider Events | ‚úÖ OK | 60/min (Free) | ‚ö†Ô∏è Symbol-f√ºr-Symbol Loop |
| **Finnhub News/Macro API** | News, Sentiment, Macro | ‚úÖ OK | 60/min (Free) | ‚ö†Ô∏è Symbol-f√ºr-Symbol Loop |

**Empfehlung:**
- Alt-Data nur √ºber Download-Skripte holen (`download_altdata_finnhub_events.py`, `download_altdata_finnhub_news_macro.py`)
- **NICHT** in Factor-Analysis-Workflows direkt API-Calls f√ºr Alt-Data machen
- Alle Alt-Data aus lokalen Parquet-Dateien laden (`output/altdata/*.parquet`)

---

## 2. Aktuelle API-Nutzung im Code

### 2.1 Preis-Daten-Quellen

**`src/assembled_core/data/data_source.py`:**

#### LocalParquetPriceDataSource ‚úÖ (Optimal)
- **Verwendung:** Prim√§r f√ºr alle Workflows
- **Performance:** ‚ö° Sehr schnell (lokale Dateien)
- **Keine API-Calls:** L√§dt nur lokale Parquet-Dateien
- **Status:** ‚úÖ Empfohlen

#### YahooPriceDataSource ‚ö†Ô∏è (Rate-Limits)
- **Verwendung:** Fallback f√ºr Live-Daten
- **Performance:** üêå Langsam bei vielen Symbols
- **Problem:** Loop √ºber Symbole (Zeile 299: `for symbol in symbols:`)
- **Rate-Limits:** Unbekannt, oft blockiert
- **Status:** ‚ö†Ô∏è Nur f√ºr kleine Universen oder als Fallback

#### FinnhubPriceDataSource ‚ö†Ô∏è (Nicht empfohlen)
- **Verwendung:** Alternative f√ºr Preise (aber nicht empfohlen!)
- **Performance:** üêå Langsam (Loop √ºber Symbole, Zeile 468: `for symbol in symbols:`)
- **Rate-Limits:** 60/min (Free Tier)
- **Problem:** 
  - **Symbol-f√ºr-Symbol Loop** (ineffizient)
  - **Keine Batch-API** verf√ºgbar
  - **Keine Delays** zwischen Requests (kann Rate-Limits √ºberschreiten)
- **Status:** ‚ö†Ô∏è Nicht f√ºr Produktions-Workflows verwenden

#### TwelveDataPriceDataSource ‚ö†Ô∏è (Sehr langsam)
- **Verwendung:** Alternative f√ºr Preise (aber nicht empfohlen!)
- **Performance:** üêå Sehr langsam (Loop √ºber Symbole, Zeile 656: `for symbol in symbols:`)
- **Rate-Limits:** 8/min (Free Tier) - sehr restriktiv
- **Problem:**
  - **Symbol-f√ºr-Symbol Loop** (ineffizient)
  - **Keine Batch-API** verf√ºgbar
  - **Sehr lange Delays** n√∂tig (7.5s zwischen Requests)
- **Status:** ‚ö†Ô∏è Nicht f√ºr Produktions-Workflows verwenden

### 2.2 Alt-Data-Quellen

**`src/assembled_core/data/altdata/finnhub_events.py`:**

#### fetch_earnings_events() ‚ö†Ô∏è (Performance-Problem)
- **Verwendung:** Download-Skripte (`download_altdata_finnhub_events.py`)
- **Performance:** üêå Langsam bei vielen Symbols
- **Problem:** 
  - **Ein API-Call f√ºr alle Symbole** (Zeile 107-140), aber dann Filterung
  - **Besser:** Batch-API nutzen, wenn verf√ºgbar
- **Rate-Limits:** 60/min (Free Tier)
- **Delays:** `RATE_LIMIT_DELAY_SECONDS = 1.0` (Zeile 33)
- **Status:** ‚ö†Ô∏è OK f√ºr Download-Skripte, aber k√∂nnte optimiert werden

#### fetch_insider_events() ‚ö†Ô∏è (Performance-Problem)
- **Verwendung:** Download-Skripte (`download_altdata_finnhub_events.py`)
- **Performance:** üêå Langsam bei vielen Symbols
- **Problem:** 
  - **Symbol-f√ºr-Symbol Loop** (Zeile 269: `for symbol in symbols:`)
  - **Keine Batch-API** verf√ºgbar
  - **Delays:** `RATE_LIMIT_DELAY_SECONDS = 1.0` zwischen Symbols
- **Status:** ‚ö†Ô∏è OK f√ºr Download-Skripte, aber sehr langsam bei gro√üen Universen

**`src/assembled_core/data/altdata/finnhub_news_macro.py`:**

#### fetch_news() ‚ö†Ô∏è (Performance-Problem)
- **Verwendung:** Download-Skripte (`download_altdata_finnhub_news_macro.py`)
- **Performance:** üêå Langsam bei vielen Symbols
- **Problem:** 
  - **Symbol-f√ºr-Symbol Loop** (Zeile 113: `for symbol in symbols:`)
  - **Keine Batch-API** verf√ºgbar
  - **Delays:** `RATE_LIMIT_DELAY_SECONDS = 1.0` zwischen Symbols
- **Status:** ‚ö†Ô∏è OK f√ºr Download-Skripte, aber sehr langsam bei gro√üen Universen

#### fetch_news_sentiment() ‚ö†Ô∏è (Performance-Problem)
- **Verwendung:** Download-Skripte (`download_altdata_finnhub_news_macro.py`)
- **Performance:** üêå Langsam (nutzt `fetch_news()` intern, also auch Symbol-Loop)
- **Status:** ‚ö†Ô∏è OK f√ºr Download-Skripte

#### fetch_macro_series() ‚úÖ (OK)
- **Verwendung:** Download-Skripte (`download_altdata_finnhub_news_macro.py`)
- **Performance:** ‚ö° OK (Loop √ºber Macro-Codes, aber typischerweise wenige Codes)
- **Status:** ‚úÖ OK

---

## 3. Performance-Probleme

### 3.1 Symbol-f√ºr-Symbol Loops (Kritisch)

**Problem:** Viele Funktionen iterieren √ºber Symbole und machen einzelne API-Calls:

1. **`YahooPriceDataSource.get_history()`** (Zeile 299)
   - Loop: `for symbol in symbols:`
   - Ein API-Call pro Symbol
   - **L√∂sung:** yfinance unterst√ºtzt Batch-Downloads! ‚Üí `yf.download(symbols)` verwenden

2. **`FinnhubPriceDataSource.get_history()`** (Zeile 468)
   - Loop: `for symbol in symbols:`
   - Ein API-Call pro Symbol
   - **Problem:** Keine Batch-API verf√ºgbar, aber keine Delays zwischen Requests
   - **L√∂sung:** Delays zwischen Requests hinzuf√ºgen

3. **`TwelveDataPriceDataSource.get_history()`** (Zeile 656)
   - Loop: `for symbol in symbols:`
   - Ein API-Call pro Symbol
   - **Problem:** Sehr restriktive Rate-Limits (8/min)
   - **L√∂sung:** Delays zwischen Requests (7.5s minimum)

4. **`fetch_insider_events()`** (Zeile 269)
   - Loop: `for symbol in symbols:`
   - Ein API-Call pro Symbol
   - **Problem:** Sehr langsam bei gro√üen Universen
   - **L√∂sung:** Batch-API pr√ºfen oder parallele Requests (mit Rate-Limit-Respektierung)

5. **`fetch_news()`** (Zeile 113)
   - Loop: `for symbol in symbols:`
   - Ein API-Call pro Symbol
   - **Problem:** Sehr langsam bei gro√üen Universen
   - **L√∂sung:** Batch-API pr√ºfen oder parallele Requests (mit Rate-Limit-Respektierung)

### 3.2 Ineffiziente DataFrame-Operationen

**Problem:** Viele kleine Merges statt einem gro√üen Merge:

1. **`build_news_sentiment_factors()`** (Zeile 241-307)
   - Loop √ºber Symbole: `for symbol in result[group_col].unique():`
   - **Zwei `merge_asof`-Calls pro Symbol** (Zeile 258, 283)
   - **Viele `pd.concat()`-Calls** (Zeile 307)
   - **L√∂sung:** Alle Symbole auf einmal mergen (mit MultiIndex oder groupby)

2. **`build_macro_regime_factors()`** (Zeile 569-590)
   - Loop √ºber Symbole: `for symbol in result[group_col].unique():`
   - **Ein `merge_asof`-Call pro Symbol** (Zeile 575)
   - **Viele `pd.concat()`-Calls** (Zeile 590)
   - **L√∂sung:** Da alle Symbole denselben Regime-Wert haben, kann man direkt mergen ohne Loop

3. **`build_earnings_surprise_factors()`** (Zeile 206-256)
   - Loop √ºber Symbole: `for symbol in result[group_col].unique():`
   - **Ein `merge_asof`-Call pro Symbol** (Zeile 230)
   - **Viele `pd.concat()`-Calls** (Zeile 256)
   - **L√∂sung:** Alle Symbole auf einmal mergen

4. **`build_insider_activity_factors()`** (Zeile 482-577)
   - Loop √ºber Symbole: `for symbol in result[group_col].unique():`
   - **Komplexe Aggregationen pro Symbol**
   - **L√∂sung:** `groupby().apply()` verwenden statt Loop

### 3.3 Rate-Limit-Handling

**Problem:** Inkonsistentes Rate-Limit-Handling:

1. **`FinnhubPriceDataSource`** (Zeile 468-525)
   - **KEINE Delays** zwischen Requests
   - **Problem:** Kann Rate-Limits √ºberschreiten (60/min)
   - **L√∂sung:** `time.sleep(1.0)` zwischen Requests hinzuf√ºgen

2. **`TwelveDataPriceDataSource`** (Zeile 656-734)
   - **KEINE Delays** zwischen Requests
   - **Problem:** Kann Rate-Limits √ºberschreiten (8/min = 7.5s zwischen Requests)
   - **L√∂sung:** `time.sleep(7.5)` zwischen Requests hinzuf√ºgen

3. **`fetch_insider_events()`** (Zeile 269-372)
   - **Delays vorhanden:** `time.sleep(RATE_LIMIT_DELAY_SECONDS)` (Zeile 368)
   - **Rate-Limit-Error-Handling:** 60s Wait bei Rate-Limit (Zeile 283-284)
   - **Status:** ‚úÖ OK

4. **`fetch_news()`** (Zeile 113-188)
   - **Delays vorhanden:** `time.sleep(RATE_LIMIT_DELAY_SECONDS)` (Zeile 184)
   - **Rate-Limit-Error-Handling:** 60s Wait bei Rate-Limit (Zeile 128-129)
   - **Status:** ‚úÖ OK

---

## 4. Dopplungen und Inkonsistenzen

### 4.1 Doppelte `_get_finnhub_session()` Funktionen

**Problem:** Zwei identische Funktionen in verschiedenen Modulen:

1. **`src/assembled_core/data/altdata/finnhub_events.py`** (Zeile 36-71)
2. **`src/assembled_core/data/altdata/finnhub_news_macro.py`** (Zeile 37-74)

**L√∂sung:** In gemeinsames Modul verschieben (z.B. `src/assembled_core/data/altdata/finnhub_common.py`)

### 4.2 Inkonsistente Error-Handling

**Problem:** Unterschiedliche Error-Handling-Strategien:

1. **YahooPriceDataSource:** Loggt Warnung, f√§hrt fort mit n√§chstem Symbol
2. **FinnhubPriceDataSource:** Loggt Warnung, f√§hrt fort mit n√§chstem Symbol
3. **TwelveDataPriceDataSource:** Loggt Warnung, f√§hrt fort mit n√§chstem Symbol
4. **Alt-Data Clients:** Loggt Warnung, gibt leeres DataFrame zur√ºck

**Status:** ‚úÖ Konsistent (alle fahren fort, keine Crashes)

### 4.3 Inkonsistente Rate-Limit-Delays

**Problem:** Unterschiedliche Delay-Werte:

1. **Finnhub Events:** `RATE_LIMIT_DELAY_SECONDS = 1.0` (Zeile 33)
2. **Finnhub News/Macro:** `RATE_LIMIT_DELAY_SECONDS = 1.0` (Zeile 34)
3. **Alpha Vantage:** `base_sleep = 13.0` (in `pull_intraday_av.py`)
4. **Twelve Data:** Keine Delays (sollte 7.5s sein)

**L√∂sung:** Zentrale Konfiguration f√ºr Rate-Limits

---

## 5. Kritische Baustellen

### 5.1 üö® KRITISCH: Symbol-f√ºr-Symbol Loops in Preis-DataSources

**Betroffen:**
- `YahooPriceDataSource.get_history()` (Zeile 299)
- `FinnhubPriceDataSource.get_history()` (Zeile 468)
- `TwelveDataPriceDataSource.get_history()` (Zeile 656)

**Problem:**
- Sehr langsam bei gro√üen Universen (100+ Symbole)
- Kann Stunden dauern
- Rate-Limits werden oft √ºberschreiten

**L√∂sung:**
1. **Yahoo:** `yf.download(symbols)` verwenden (Batch-Download)
2. **Finnhub/Twelve Data:** Delays zwischen Requests hinzuf√ºgen
3. **Empfehlung:** Immer `data_source="local"` verwenden, Preise nur √ºber Download-Skripte aktualisieren

### 5.2 ‚ö†Ô∏è WICHTIG: Ineffiziente DataFrame-Merges

**Betroffen:**
- `build_news_sentiment_factors()` (Zeile 241-307)
- `build_macro_regime_factors()` (Zeile 569-590)
- `build_earnings_surprise_factors()` (Zeile 206-256)
- `build_insider_activity_factors()` (Zeile 482-577)

**Problem:**
- Loop √ºber Symbole mit vielen kleinen Merges
- `pd.concat()` wird oft aufgerufen
- Langsam bei gro√üen Universen

**L√∂sung:**
- `groupby().apply()` verwenden statt Loops
- Oder: Alle Symbole auf einmal mergen (mit MultiIndex oder groupby)

### 5.3 ‚ö†Ô∏è WICHTIG: Fehlende Rate-Limit-Delays

**Betroffen:**
- `FinnhubPriceDataSource.get_history()` (Zeile 468)
- `TwelveDataPriceDataSource.get_history()` (Zeile 656)

**Problem:**
- Keine Delays zwischen Requests
- Rate-Limits werden √ºberschreiten

**L√∂sung:**
- `time.sleep()` zwischen Requests hinzuf√ºgen
- Finnhub: 1.0s Delay
- Twelve Data: 7.5s Delay (8/min = 7.5s)

### 5.4 ‚ö†Ô∏è MITTEL: Doppelte `_get_finnhub_session()` Funktionen

**Betroffen:**
- `finnhub_events.py` und `finnhub_news_macro.py`

**Problem:**
- Code-Duplikation
- Wartungsaufwand

**L√∂sung:**
- In gemeinsames Modul verschieben (`finnhub_common.py`)

### 5.5 ‚ö†Ô∏è MITTEL: Ineffiziente Trend-Berechnung

**Betroffen:**
- `build_news_sentiment_factors()` (Zeile 166-179, 221-234)

**Problem:**
- `compute_trend()` Funktion macht Loop √ºber alle Indizes
- `np.polyfit()` wird f√ºr jedes Fenster aufgerufen
- Langsam bei langen Zeitreihen

**L√∂sung:**
- Vectorisierte Berechnung verwenden (z.B. `np.polyfit` auf gesamte Serie anwenden)

---

## 6. Empfehlungen

### 6.1 Sofortige Ma√ünahmen (Kritisch)

1. **Alle Preis-DataSources:** Immer `data_source="local"` verwenden
   - Preise nur √ºber Download-Skripte aktualisieren
   - Keine API-Calls in Backtests oder Factor-Analysis-Workflows

2. **Rate-Limit-Delays hinzuf√ºgen:**
   - `FinnhubPriceDataSource`: `time.sleep(1.0)` zwischen Requests
   - `TwelveDataPriceDataSource`: `time.sleep(7.5)` zwischen Requests

3. **YahooPriceDataSource optimieren:**
   - `yf.download(symbols)` verwenden statt Loop

### 6.2 Mittelfristige Ma√ünahmen (Wichtig)

1. **DataFrame-Merges optimieren:**
   - `groupby().apply()` verwenden statt Loops
   - Alle Symbole auf einmal mergen

2. **Code-Duplikation reduzieren:**
   - `_get_finnhub_session()` in gemeinsames Modul verschieben

3. **Trend-Berechnung optimieren:**
   - Vectorisierte Berechnung verwenden

### 6.3 Langfristige Ma√ünahmen (Nice-to-Have)

1. **Batch-APIs nutzen:**
   - Pr√ºfen, ob Finnhub Batch-APIs f√ºr Insider/News hat
   - Parallele Requests mit Rate-Limit-Respektierung

2. **Caching implementieren:**
   - API-Responses cachen (z.B. f√ºr Macro-Daten)
   - TTL-basiertes Caching

3. **Zentrale Rate-Limit-Konfiguration:**
   - Alle Rate-Limits in einer Konfigurationsdatei
   - Automatisches Delay-Management

---

## 7. Zusammenfassung

### ‚úÖ Was gut funktioniert:
- **LocalParquetPriceDataSource:** Sehr schnell, keine API-Calls
- **Alt-Data Download-Skripte:** Rate-Limits werden respektiert
- **Error-Handling:** Robust, keine Crashes

### ‚ö†Ô∏è Was verbessert werden muss:
- **Symbol-f√ºr-Symbol Loops:** Sehr langsam bei gro√üen Universen
- **Ineffiziente DataFrame-Merges:** Viele kleine Merges statt einem gro√üen
- **Fehlende Rate-Limit-Delays:** In Preis-DataSources
- **Code-Duplikation:** `_get_finnhub_session()` doppelt vorhanden

### üö® Kritische Punkte:
1. **Preis-APIs in Workflows:** Sollten **NIE** verwendet werden, nur `data_source="local"`
2. **Rate-Limit-√úberschreitungen:** K√∂nnen zu API-Blockierungen f√ºhren
3. **Performance bei gro√üen Universen:** Kann Stunden dauern

---

## 8. N√§chste Schritte

1. **Sofort:** Rate-Limit-Delays zu Preis-DataSources hinzuf√ºgen
2. **Sofort:** YahooPriceDataSource optimieren (Batch-Download)
3. **Kurzfristig:** DataFrame-Merges optimieren
4. **Mittelfristig:** Code-Duplikation reduzieren
5. **Langfristig:** Batch-APIs und Caching implementieren

